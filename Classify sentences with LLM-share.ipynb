{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77125,"status":"ok","timestamp":1751989005255,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"FAclL2g1nck2","outputId":"776b16f9-6118-464c-8080-9264aad127d8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1c9DqXkBnkX6","executionInfo":{"status":"ok","timestamp":1751989005851,"user_tz":-120,"elapsed":601,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"}}},"outputs":[],"source":["\n","# Import libraries\n","import pandas as pd\n","import numpy as np\n","from typing import List, Dict, Tuple\n","import requests\n","import json\n","import time\n","import re\n","from tqdm import tqdm\n","import logging\n","import os\n","from google.colab import files, drive\n","import warnings\n","import pyarrow # Import pyarrow\n","#warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8169,"status":"ok","timestamp":1751989014018,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"786db89f","outputId":"c0066baf-2ba4-4b20-89d1-4b1619082914"},"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Setting up Climate Mitigation Classification Pipeline\n","============================================================\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h‚úÖ Setup complete!\n"]}],"source":["# Cell 1: Install dependencies and setup\n","print(\"üöÄ Setting up Climate Mitigation Classification Pipeline\")\n","print(\"=\" * 60)\n","\n","# Install required packages\n","# Added pyarrow for reading feather files\n","!pip install -q requests pandas numpy tqdm groq pyarrow\n","\n","\n","# Set up logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n","logger = logging.getLogger(__name__)\n","\n","print(\"‚úÖ Setup complete!\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":106},"executionInfo":{"elapsed":25,"status":"error","timestamp":1751989014071,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"8b8d99d4","outputId":"dc42104b-a13a-4197-cc2b-8df07a046427"},"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (ipython-input-4-772916558.py, line 19)","traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-4-772916558.py\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    api_key =\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}],"source":["\n","# Cell 2: Configuration and API Setup\n","print(\"üîß Configuration Setup\")\n","print(\"-\" * 25)\n","\n","# Configuration\n","CONFIG = {\n","    'groq_api_key': '',  # Will be set below\n","    'groq_model': 'llama-3.1-8b-instant',\n","    'n_per_institution': 10000,  # Total sample size\n","    'batch_size': 50,           # Reduced for better checkpoint frequency\n","    'delay': 1.0,               # Increased default delay for rate limiting\n","    'max_retries': 5,           # Maximum retries for rate limited requests\n","    'retry_delay': 60,          # Base delay for retries (seconds)\n","    'backoff_multiplier': 2     # Exponential backoff multiplier\n","}\n","# Get Groq API key\n","print(\"üîë Please enter your Groq API key:\")\n","print(\"(Get it from: https://console.groq.com/keys)\")\n","api_key =\n","\n","if not api_key:\n","    print(\"‚ùå API key is required!\")\n","    raise ValueError(\"API key cannot be empty\")\n","\n","CONFIG['groq_api_key'] = api_key\n","print(\"‚úÖ API key configured!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":86206,"status":"aborted","timestamp":1751989014068,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"f16a26ae"},"outputs":[],"source":["# Cell 3: Mount Google Drive\n","print(\"üíæ Google Drive Setup\")\n","print(\"-\" * 25)\n","\n","try:\n","    drive.mount('/content/drive')\n","    DRIVE_PATH = '/content/drive/MyDrive/Climate Mitigation Council Sentences/'\n","\n","    # Create directory if it doesn't exist\n","    os.makedirs(DRIVE_PATH, exist_ok=True)\n","    print(f\"‚úÖ Google Drive mounted: {DRIVE_PATH}\")\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è Google Drive mount failed: {e}\")\n","    DRIVE_PATH = './'  # Use local directory as fallback\n","    print(\"üìÅ Using local directory for file storage\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":76838,"status":"aborted","timestamp":1751989014073,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"60d1afb4"},"outputs":[],"source":["# Cell 4: Data Upload\n","print(\"üì§ Data Upload\")\n","print(\"-\" * 15)\n","\n","# Option 1: Upload from computer\n","print(\"Choose your data source:\")\n","print(\"1. Upload CSV file from your computer\")\n","print(\"2. Upload from preselected directory\")\n","print(\"3. Use sample data for testing\")\n","print(\"4. Load Feather file from Google Drive\")\n","print(\"5. Load existing results file for reclassification\")\n","print(\"6. Load checkpoint file from Google Drive to resume\") # New option\n","\n","data_choice = input(\"Enter choice (1/2/3/4/5/6): \").strip()\n","\n","df = None # Initialize df\n","is_reclassification = False\n","is_resuming_from_checkpoint = False # New flag\n","\n","if data_choice == \"1\":\n","    print(\"üìÅ Please upload your CSV file with political speeches...\")\n","    uploaded = files.upload()\n","    if uploaded:\n","        filename = list(uploaded.keys())[0]\n","        try:\n","            df = pd.read_csv(filename)\n","            print(f\"‚úÖ Loaded {len(df)} sentences from {filename}\")\n","        except Exception as e:\n","            print(f\"‚ùå Error loading file {filename}: {e}\")\n","    else:\n","        print(\"‚ùå No file uploaded.\")\n","\n","elif data_choice == \"2\":\n","   # filename = input(\"Enter CSV filename (including path if needed) in your Google Drive: \")\n","    try:\n","        df = pd.read_csv('/content/drive/MyDrive/Climate Mitigation Council Sentences/stratified_sample.csv')\n","        print(f\"‚úÖ Loaded {len(df)} sentences from Google Drive\")\n","    except Exception as e:\n","        print(f\"‚ùå File not found or error loading file. Please check the filename and ensure Google Drive is mounted. Error: {e}\")\n","\n","elif data_choice == \"3\":\n","    # Create sample data for testing\n","    print(\"üß™ Creating sample dataset for testing...\")\n","    sample_data = {\n","        'current': [\n","            'The European Green Deal aims to reduce carbon emissions by 2030.',\n","            'We need to invest more in renewable energy infrastructure.',\n","            'The parliament voted on budget allocations for next year.',\n","            'Climate change mitigation requires immediate policy action.',\n","            'The economic situation has improved significantly.',\n","            'Solar and wind energy are key to carbon neutrality.',\n","            'Education reform is essential for our future.',\n","            'The EU ETS system helps reduce greenhouse gas emissions.',\n","            'Healthcare spending increased by 15% this quarter.',\n","            'Forest restoration enhances natural carbon sinks.'\n","        ] * 1000,  # Create 10k sample sentences\n","        'institution': ['European Parliament', 'European Commission'] * 5000,\n","        'how_many_words_in_climate_mitigation_dictionary': [2, 3, 0, 4, 0, 3, 0, 5, 0, 2] * 1000\n","    }\n","    df = pd.DataFrame(sample_data)\n","    print(f\"‚úÖ Created sample dataset with {len(df)} sentences\")\n","\n","elif data_choice == \"4\":\n","     filename = input(\"Enter Feather filename (including path if needed) in your Google Drive: \")\n","     try:\n","         df = pd.read_feather(f'/content/drive/MyDrive/{filename}')\n","         print(f\"‚úÖ Loaded {len(df)} sentences from Feather file in Google Drive\")\n","     except Exception as e:\n","         print(f\"‚ùå File not found or error loading file. Please check the filename and ensure Google Drive is mounted. Error: {e}\")\n","\n","elif data_choice == \"5\":  # Option for reclassification\n","    filename = input(\"Enter results CSV filename (including path if needed) in your Google Drive: \")\n","    try:\n","        df = pd.read_csv(f'/content/drive/MyDrive/{filename}')\n","        print(f\"‚úÖ Loaded {len(df)} sentences from existing results file\")\n","        is_reclassification = True\n","\n","        # Check for failed classifications\n","        if 'llm_explanation' in df.columns:\n","            failed_mask = (\n","                df['llm_explanation'].str.contains('Error: HTTP 429', na=False) |\n","                df['llm_explanation'].str.contains('Rate limit exceeded', na=False) |\n","                df['llm_explanation'].str.contains('Error:', na=False)\n","            )\n","            failed_count = failed_mask.sum()\n","            print(f\"üìä Found {failed_count} failed classifications that can be retried\")\n","\n","            if failed_count > 0:\n","                print(\"Failed error types:\")\n","                error_types = df[failed_mask]['llm_explanation'].value_counts()\n","                for error, count in error_types.head(5).items():\n","                    print(f\"   ‚Ä¢ {error}: {count} cases\")\n","        else:\n","            print(\"‚ö†Ô∏è No 'llm_explanation' column found in the file\")\n","\n","    except Exception as e:\n","        print(f\"‚ùå File not found or error loading file. Error: {e}\")\n","\n","elif data_choice == \"6\": # New option for loading checkpoint\n","    filename = input(\"Enter checkpoint CSV filename (including path if needed) in your Google Drive: \")\n","    try:\n","        df = pd.read_csv(f'/content/drive/MyDrive/{filename}')\n","        print(f\"‚úÖ Loaded {len(df)} sentences from checkpoint file\")\n","        is_resuming_from_checkpoint = True # Set the flag\n","        print(\"üîÑ Resuming classification from checkpoint...\")\n","\n","        # Show current status from checkpoint\n","        if 'processing_status' in df.columns:\n","            status_counts = df['processing_status'].value_counts()\n","            print(\"Current processing status in checkpoint:\")\n","            for status, count in status_counts.items():\n","                print(f\"   {status}: {count}\")\n","        else:\n","             print(\"‚ö†Ô∏è 'processing_status' column not found in checkpoint. Assuming all need processing.\")\n","\n","\n","    except Exception as e:\n","        print(f\"‚ùå File not found or error loading file. Error: {e}\")\n","\n","else:\n","    print(\"‚ö†Ô∏è Invalid choice. Please enter 1, 2, 3, 4, 5, or 6.\")\n","\n","\n","# Verify required columns (removed 'institution' from requirement list)\n","required_cols = ['sentence', 'how_many_words_in_climate_mitigation_dictionary']\n","\n","if df is not None:\n","    missing_cols = [col for col in required_cols if col not in df.columns]\n","\n","    if missing_cols:\n","        print(f\"‚ùå Missing required columns: {missing_cols}\")\n","        print(f\"Available columns: {list(df.columns)}\")\n","        print(\"\\nüö® Please ensure your data file contains the required columns.\")\n","        df = None\n","    else:\n","        print(\"‚úÖ All required columns found!\")\n","        print(f\"üìä Dataset shape: {df.shape}\")\n","        if 'institution' in df.columns:\n","             print(f\"üèõÔ∏è  Institutions: {df['institution'].unique()}\")\n","else:\n","    print(\"‚ùå Data loading failed or cancelled or invalid choice. Cannot proceed with classification.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":122,"status":"ok","timestamp":1751797327158,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"2bb0370c","outputId":"543f4393-40d6-4999-878b-4cb2c6516720"},"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Enhanced Climate Classification Class defined!\n"]}],"source":["# Cell 5: Enhanced Climate Classification Class\n","class ClimateMitigationClassifier:\n","    def __init__(self, groq_api_key: str, model: str = 'llama-3.1-8b-instant',\n","                 max_retries: int = 5, retry_delay: int = 60, backoff_multiplier: float = 2):\n","        \"\"\"Initialize the classifier with Groq API and retry configuration\"\"\"\n","        self.groq_api_key = groq_api_key\n","        self.model = model\n","        self.max_retries = max_retries\n","        self.retry_delay = retry_delay\n","        self.backoff_multiplier = backoff_multiplier\n","        self.prompt_template = \"\"\"**Prompt:**\n","Determine whether the following sentence is about **climate mitigation**.\n","A sentence is about *climate mitigation* if it refers to efforts, measures, technologies, or policies aimed at **reducing or preventing greenhouse gas (GHG) emissions** or **enhancing carbon sinks**, with the goal of **limiting climate change** and achieving **climate neutrality**, as targeted by the European Union.\n","\n","Relevant topics include:\n","* Reducing emissions in sectors like energy, transport, industry, or agriculture\n","* Promoting renewable energy, energy efficiency, or low-carbon technologies\n","* Implementing EU climate policies like the European Green Deal, EU ETS, or Fit for 55\n","* Supporting carbon removal, sustainable land use, or natural carbon sinks\n","\n","Now, analyze the sentence below and respond with either **\"1\"** if it is about climate mitigation in the EU policy context, or **\"0\"** if it is not. Provide a brief explanation for your answer.\n","\n","Sentence: \"{sentence}\"\n","\n","Response:\"\"\"\n","\n","    def create_stratified_sample(self, df: pd.DataFrame,\n","                                 dictionary_col: str = 'how_many_words_in_climate_mitigation_dictionary',\n","                                 institution_col: str = 'institution',\n","                                 n_total_sample: int = 1000) -> pd.DataFrame:\n","        \"\"\"Create a stratified sample, aiming for 50% sentences with dictionary terms.\"\"\"\n","        sampled_dfs = []\n","\n","        print(f\"üéØ Creating stratified sample (total target: {n_total_sample} sentences)\")\n","\n","        if institution_col in df.columns:\n","            groups = df.groupby(institution_col)\n","            print(f\"Grouping by institution ({len(df[institution_col].unique())} unique institutions)\")\n","            n_per_institution = n_total_sample // len(df[institution_col].unique())\n","            print(f\"Aiming for ~{n_per_institution} sentences per institution\")\n","        else:\n","            groups = [(None, df)]\n","            print(\"No institution column found. Sampling from the entire dataset.\")\n","\n","        for group_name, group_df in groups:\n","            if group_name is not None:\n","                 print(f\"\\nüìã Processing group: {group_name}\")\n","\n","            with_terms = group_df[group_df[dictionary_col] > 0]\n","            without_terms = group_df[group_df[dictionary_col] == 0]\n","\n","            print(f\"   Available: {len(with_terms)} with terms, {len(without_terms)} without terms\")\n","\n","            if institution_col in df.columns:\n","                 n_with_terms = min(n_per_institution // 2, len(with_terms))\n","                 n_without_terms = min(n_per_institution // 2, len(without_terms))\n","                 target_group_sample = n_per_institution\n","            else:\n","                 n_with_terms = min(n_total_sample // 2, len(with_terms))\n","                 n_without_terms = min(n_total_sample // 2, len(without_terms))\n","                 target_group_sample = n_total_sample\n","\n","            total_available_in_group = len(with_terms) + len(without_terms)\n","\n","            if total_available_in_group < target_group_sample:\n","                 print(f\"   ‚ö†Ô∏è  Group has only {total_available_in_group} sentences, using all available\")\n","                 n_with_terms = len(with_terms)\n","                 n_without_terms = len(without_terms)\n","            else:\n","                if n_with_terms < target_group_sample // 2:\n","                    n_without_terms = min(target_group_sample - n_with_terms, len(without_terms))\n","                elif n_without_terms < target_group_sample // 2:\n","                    n_with_terms = min(target_group_sample - n_without_terms, len(with_terms))\n","\n","            sampled_with = with_terms.sample(n=n_with_terms, random_state=42) if n_with_terms > 0 else pd.DataFrame(columns=group_df.columns)\n","            sampled_without = without_terms.sample(n=n_without_terms, random_state=42) if n_without_terms > 0 else pd.DataFrame(columns=group_df.columns)\n","\n","            group_sample = pd.concat([sampled_with, sampled_without], ignore_index=True)\n","            sampled_dfs.append(group_sample)\n","\n","            if group_name is not None:\n","                 print(f\"   ‚úÖ Sampled {len(group_sample)} sentences for group {group_name}\")\n","            else:\n","                 print(f\"   ‚úÖ Sampled {len(group_sample)} sentences from the dataset\")\n","\n","        final_sample = pd.concat(sampled_dfs, ignore_index=True)\n","        print(f\"\\nüéâ Total final sample size: {len(final_sample)} sentences\")\n","\n","        return final_sample\n","\n","    def query_groq_with_retry(self, sentence: str) -> Tuple[int, str]:\n","        \"\"\"Query Groq API with exponential backoff retry logic\"\"\"\n","        for attempt in range(self.max_retries + 1):\n","            try:\n","                classification, explanation = self.query_groq(sentence)\n","\n","                # Check if the response indicates a rate limit error\n","                if \"Error: HTTP 429\" in explanation or \"Rate limit exceeded\" in explanation:\n","                    if attempt < self.max_retries:\n","                        wait_time = self.retry_delay * (self.backoff_multiplier ** attempt)\n","                        print(f\"‚ö†Ô∏è Rate limit hit, waiting {wait_time:.0f}s before retry {attempt + 1}/{self.max_retries}\")\n","                        time.sleep(wait_time)\n","                        continue\n","                    else:\n","                        print(f\"‚ùå Max retries reached for rate limiting\")\n","                        return 0, f\"Error: Max retries exceeded due to rate limiting\"\n","\n","                # Successful response\n","                return classification, explanation\n","\n","            except Exception as e:\n","                if attempt < self.max_retries:\n","                    wait_time = self.retry_delay * (self.backoff_multiplier ** attempt)\n","                    print(f\"‚ö†Ô∏è Error occurred, waiting {wait_time:.0f}s before retry {attempt + 1}/{self.max_retries}: {str(e)}\")\n","                    time.sleep(wait_time)\n","                    continue\n","                else:\n","                    return 0, f\"Error: Max retries exceeded - {str(e)}\"\n","\n","        return 0, \"Error: Unexpected retry loop exit\"\n","\n","    def query_groq(self, sentence: str) -> Tuple[int, str]:\n","        \"\"\"Query Groq API for classification\"\"\"\n","        headers = {\n","            \"Authorization\": f\"Bearer {self.groq_api_key}\",\n","            \"Content-Type\": \"application/json\"\n","        }\n","\n","        payload = {\n","            \"model\": self.model,\n","            \"messages\": [\n","                {\"role\": \"user\", \"content\": self.prompt_template.format(sentence=sentence)}\n","            ],\n","            \"temperature\": 0.1,\n","            \"max_tokens\": 150\n","        }\n","\n","        try:\n","            response = requests.post(\n","                \"https://api.groq.com/openai/v1/chat/completions\",\n","                headers=headers,\n","                json=payload,\n","                timeout=30\n","            )\n","\n","            if response.status_code == 200:\n","                result = response.json()\n","                generated_text = result['choices'][0]['message']['content']\n","                return self._parse_llm_response(generated_text)\n","            else:\n","                error_msg = f\"HTTP {response.status_code}\"\n","                if response.status_code == 401:\n","                    error_msg += \" - Invalid API key\"\n","                elif response.status_code == 429:\n","                    error_msg += \" - Rate limit exceeded\"\n","                elif response.status_code == 503:\n","                    error_msg += \" - Service unavailable\"\n","                return 0, f\"Error: {error_msg}\"\n","\n","        except Exception as e:\n","            return 0, f\"Error: {str(e)}\"\n","\n","    def _parse_llm_response(self, response_text: str) -> Tuple[int, str]:\n","        \"\"\"Parse LLM response to extract binary classification\"\"\"\n","        response_text = response_text.strip()\n","\n","        if \"**1**\" in response_text or response_text.startswith(\"1\"):\n","            return 1, response_text\n","        elif \"**0**\" in response_text or response_text.startswith(\"0\"):\n","            return 0, response_text\n","        elif re.search(r'\\b1\\b', response_text) and not re.search(r'\\b0\\b', response_text):\n","            return 1, response_text\n","        elif re.search(r'\\b0\\b', response_text) and not re.search(r'\\b1\\b', response_text):\n","            return 0, response_text\n","        else:\n","            climate_indicators = ['climate', 'emission', 'carbon', 'renewable', 'green deal', 'mitigation', 'ghg']\n","            if any(indicator.lower() in response_text.lower() for indicator in climate_indicators):\n","                return 1, response_text\n","            else:\n","                return 0, response_text\n","\n","    def classify_sentences(self, df: pd.DataFrame,\n","                          sentence_col: str = 'sentence',\n","                          batch_size: int = 100,\n","                          delay: float = 0.3,\n","                          reclassify_failed: bool = False) -> pd.DataFrame:\n","        \"\"\"Classify sentences using Groq API with improved error handling\"\"\"\n","        results_df = df.copy()\n","\n","        # Initialize columns if they don't exist\n","        if 'is_climate_LLM' not in results_df.columns:\n","            results_df['is_climate_LLM'] = 0\n","        if 'llm_explanation' not in results_df.columns:\n","            results_df['llm_explanation'] = \"\"\n","        if 'processing_status' not in results_df.columns:\n","            results_df['processing_status'] = \"pending\"\n","\n","        # Determine which sentences to process\n","        if reclassify_failed:\n","            # Only process sentences with errors or specific failed statuses\n","            failed_mask = (\n","                results_df['llm_explanation'].str.contains('Error:', na=False) |\n","                results_df['processing_status'].str.contains('error', na=False) |\n","                (results_df['processing_status'] == 'pending')\n","            )\n","            sentences_to_process = results_df[failed_mask].index.tolist()\n","            print(f\"üîÑ Reclassifying {len(sentences_to_process)} failed/pending sentences...\")\n","        else:\n","            # Process all sentences\n","            sentences_to_process = df.index.tolist()\n","            print(f\"ü§ñ Starting classification of {len(sentences_to_process)} sentences...\")\n","\n","        if not sentences_to_process:\n","            print(\"‚úÖ No sentences need processing!\")\n","            return results_df\n","\n","        print(f\"‚è±Ô∏è  Estimated time: ~{len(sentences_to_process) * delay / 60:.1f} minutes\")\n","\n","        # Process sentences with progress bar\n","        processed_count = 0\n","        for idx in tqdm(sentences_to_process, desc=\"üîç Classifying\"):\n","            sentence = results_df.loc[idx, sentence_col]\n","\n","            # Skip if sentence is too short\n","            if pd.isna(sentence) or len(sentence.strip()) < 10:\n","                results_df.at[idx, 'processing_status'] = \"skipped_short\"\n","                continue\n","\n","            try:\n","                # Query Groq API with retry logic\n","                classification, explanation = self.query_groq_with_retry(sentence)\n","\n","                # Store results\n","                results_df.at[idx, 'is_climate_LLM'] = classification\n","                results_df.at[idx, 'llm_explanation'] = explanation\n","                results_df.at[idx, 'processing_status'] = \"completed\"\n","                processed_count += 1\n","\n","                # Rate limiting\n","                time.sleep(delay)\n","\n","                # Save checkpoint\n","                if processed_count % batch_size == 0:\n","                    save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","                    checkpoint_file = f\"{save_path}checkpoint_processed_{processed_count}.csv\"\n","                    try:\n","                        results_df.to_csv(checkpoint_file, index=False)\n","                        completed = (results_df['processing_status'] == 'completed').sum()\n","                        print(f\"\\nüíæ Checkpoint saved: {completed}/{len(results_df)} total completed at {checkpoint_file}\")\n","                    except Exception as e:\n","                         print(f\"\\n‚ö†Ô∏è Could not save checkpoint to {checkpoint_file}: {e}\")\n","                         try:\n","                             local_checkpoint_file = f\"./checkpoint_processed_{processed_count}_local.csv\"\n","                             results_df.to_csv(local_checkpoint_file, index=False)\n","                             print(f\"üíæ Checkpoint saved locally: {local_checkpoint_file}\")\n","                         except Exception as local_e:\n","                             print(f\"‚ùå Could not save checkpoint locally either: {local_e}\")\n","\n","            except Exception as e:\n","                logger.error(f\"Error processing sentence {idx}: {str(e)}\")\n","                results_df.at[idx, 'processing_status'] = f\"error: {str(e)}\"\n","                results_df.at[idx, 'llm_explanation'] = str(e)\n","\n","        print(f\"üéâ Processing complete! Processed {processed_count} sentences in this run.\")\n","        return results_df\n","\n","    def generate_summary_stats(self, results_df: pd.DataFrame) -> Dict:\n","        \"\"\"Generate summary statistics\"\"\"\n","        total = len(results_df)\n","        climate_count = (results_df['is_climate_LLM'] == 1).sum()\n","\n","        # Count processing statuses\n","        completed_count = (results_df['processing_status'] == 'completed').sum()\n","        failed_count = results_df['processing_status'].str.contains('error', na=False).sum()\n","        pending_count = (results_df['processing_status'] == 'pending').sum()\n","\n","        stats = {\n","            'total_sentences': total,\n","            'climate_mitigation_sentences': climate_count,\n","            'non_climate_sentences': total - climate_count,\n","            'climate_percentage': round(climate_count / total * 100, 2) if total > 0 else 0,\n","            'processing_success_rate': round(completed_count / total * 100, 2) if total > 0 else 0,\n","            'completed_sentences': completed_count,\n","            'failed_sentences': failed_count,\n","            'pending_sentences': pending_count\n","        }\n","\n","        # Stats by institution (only if column exists)\n","        if 'institution' in results_df.columns:\n","            try:\n","                inst_stats = results_df.groupby('institution').agg({\n","                    'is_climate_LLM': ['count', 'sum', lambda x: round(x.mean() * 100, 2) if x.count() > 0 else 0]\n","                })\n","                inst_stats.columns = ['Total', 'Climate', 'Climate_%']\n","                stats['by_institution'] = inst_stats.to_dict(orient='index')\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Could not generate stats by institution: {e}\")\n","\n","        # Stats by dictionary presence\n","        try:\n","            dict_stats = results_df.groupby(\n","                results_df['how_many_words_in_climate_mitigation_dictionary'] > 0\n","            ).agg({\n","                'is_climate_LLM': ['count', 'sum', lambda x: round(x.mean() * 100, 2) if x.count() > 0 else 0]\n","            })\n","            dict_stats.columns = ['Total', 'Climate', 'Climate_%']\n","            dict_stats.index = ['Without_Dict_Terms', 'With_Dict_Terms']\n","            stats['by_dictionary_presence'] = dict_stats.to_dict(orient='index')\n","        except Exception as e:\n","             print(f\"‚ö†Ô∏è Could not generate stats by dictionary presence: {e}\")\n","\n","        return stats\n","\n","print(\"‚úÖ Enhanced Climate Classification Class defined!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1751797332383,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"0b59a168","outputId":"ac1ea96e-5266-483c-9881-57fc79be2bd1"},"outputs":[{"output_type":"stream","name":"stdout","text":["üîÑ Resuming from Checkpoint\n","-------------------------\n","‚úÖ Using loaded checkpoint data.\n","Current processing status in checkpoint:\n","   completed: 2200\n","   skipped_short: 13\n"]}],"source":["# Cell 6: Choose Processing Mode\n","if df is not None:\n","    if is_resuming_from_checkpoint: # New check for resuming\n","        print(\"üîÑ Resuming from Checkpoint\")\n","        print(\"-\" * 25)\n","        sample_df = df # Use the loaded checkpoint data directly\n","        reclassify_mode = True # We are effectively reclassifying/completing the remaining\n","        print(\"‚úÖ Using loaded checkpoint data.\")\n","\n","        # Show current status from checkpoint\n","        if 'processing_status' in sample_df.columns:\n","            status_counts = sample_df['processing_status'].value_counts()\n","            print(\"Current processing status in checkpoint:\")\n","            for status, count in status_counts.items():\n","                print(f\"   {status}: {count}\")\n","        else:\n","             print(\"‚ö†Ô∏è 'processing_status' column not found in checkpoint. Assuming all need processing.\")\n","\n","\n","    elif is_reclassification:\n","        print(\"üîÑ Reclassification Mode\")\n","        print(\"-\" * 25)\n","\n","        # Show current status\n","        if 'processing_status' in df.columns:\n","            status_counts = df['processing_status'].value_counts()\n","            print(\"Current processing status:\")\n","            for status, count in status_counts.items():\n","                print(f\"   {status}: {count}\")\n","\n","        # Ask what to reclassify\n","        print(\"\\nWhat would you like to reclassify?\")\n","        print(\"1. Only failed/error sentences\")\n","        print(\"2. All sentences (complete reclassification)\")\n","\n","        reclassify_choice = input(\"Enter choice (1/2): \").strip()\n","\n","        if reclassify_choice == \"1\":\n","            reclassify_mode = True\n","            sample_df = df  # Use the full loaded dataset\n","            print(\"‚úÖ Will reclassify only failed sentences\")\n","        elif reclassify_choice == \"2\":\n","            reclassify_mode = False\n","            sample_df = df\n","            print(\"‚úÖ Will reclassify all sentences\")\n","        else:\n","            print(\"‚ùå Invalid choice. Defaulting to failed sentences only.\")\n","            reclassify_mode = True\n","            sample_df = df\n","    else:\n","        print(\"üéØ Creating Stratified Sample\")\n","        print(\"-\" * 30)\n","\n","        # Initialize classifier for sampling\n","        classifier = ClimateMitigationClassifier(\n","            CONFIG['groq_api_key'],\n","            CONFIG['groq_model'],\n","            CONFIG['max_retries'],\n","            CONFIG['retry_delay'],\n","            CONFIG['backoff_multiplier']\n","        )\n","\n","        # Create stratified sample\n","        sample_df = classifier.create_stratified_sample(\n","            df,\n","            n_total_sample=CONFIG['n_per_institution']\n","        )\n","\n","        print(f\"üìà Sample Statistics:\")\n","        print(f\"   Total sentences: {len(sample_df)}\")\n","        if 'how_many_words_in_climate_mitigation_dictionary' in sample_df.columns:\n","            print(f\"   With dict terms: {(sample_df['how_many_words_in_climate_mitigation_dictionary'] > 0).sum()}\")\n","            print(f\"   Without dict terms: {(sample_df['how_many_words_in_climate_mitigation_dictionary'] == 0).sum()}\")\n","\n","        # Save sample for backup\n","        save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","        sample_file = f\"{save_path}stratified_sample.csv\"\n","        try:\n","            sample_df.to_csv(sample_file, index=False)\n","            print(f\"üíæ Sample saved: {sample_file}\")\n","        except Exception as e:\n","            print(f\"‚ö†Ô∏è Could not save sample file to {sample_file}: {e}\")\n","            try:\n","                 local_sample_file = f\"./stratified_sample_local.csv\"\n","                 sample_df.to_csv(local_sample_file, index=False)\n","                 print(f\"üíæ Sample saved locally: {local_sample_file}\")\n","            except Exception as local_e:\n","                 print(f\"‚ùå Could not save sample file locally either: {local_e}\")\n","\n","        reclassify_mode = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"2302f87a","outputId":"74638759-1148-4a5c-9955-d27900b5e722"},"outputs":[{"output_type":"stream","name":"stdout","text":["üöÄ Starting LLM Classification\n","-----------------------------------\n","üîÑ Resuming classification. Found 7800 sentences not yet completed.\n","About to classify 7800 sentences\n","Estimated cost: FREE (Groq)\n","Estimated time: ~130.0 minutes\n","Max retries per sentence: 5\n","Base retry delay: 60 seconds\n","Proceed with classification? (y/n): y\n","ü§ñ Starting classification...\n","Starting processing loop for 7800 sentences...\n"]},{"output_type":"stream","name":"stderr","text":["üîç Classifying:   0%|          | 39/7800 [00:34<2:50:33,  1.32s/it]"]},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è Rate limit hit, waiting 60s before retry 1/5\n"]},{"output_type":"stream","name":"stderr","text":["üîç Classifying:   1%|          | 49/7800 [01:47<4:24:36,  2.05s/it]"]}],"source":["# Cell 7: Run Classification\n","if 'sample_df' in locals() and sample_df is not None:\n","    print(\"üöÄ Starting LLM Classification\")\n","    print(\"-\" * 35)\n","\n","    # Initialize classifier with retry configuration\n","    classifier = ClimateMitigationClassifier(\n","        CONFIG['groq_api_key'],\n","        CONFIG['groq_model'],\n","        CONFIG['max_retries'],\n","        CONFIG['retry_delay'],\n","        CONFIG['backoff_multiplier']\n","    )\n","\n","    # Determine sentences to process based on mode\n","    if is_resuming_from_checkpoint or (is_reclassification and reclassify_mode):\n","        # Filter for sentences that are not 'completed' when resuming or reclassifying failed\n","        unprocessed_mask = (\n","            sample_df['processing_status'] != 'completed'\n","        )\n","        sentences_to_process_df = sample_df[unprocessed_mask]\n","        sentences_to_process_indices = sentences_to_process_df.index.tolist()\n","        sentences_count = len(sentences_to_process_indices)\n","\n","        if is_resuming_from_checkpoint:\n","            print(f\"üîÑ Resuming classification. Found {sentences_count} sentences not yet completed.\")\n","        else: # Must be reclassification mode (option 5, choice 1)\n","             print(f\"üîÑ Reclassifying failed/pending sentences. Found {sentences_count} to reprocess.\")\n","\n","\n","    else: # Normal classification (new data or reclassify all)\n","        sentences_to_process_df = sample_df\n","        sentences_to_process_indices = sample_df.index.tolist()\n","        sentences_count = len(sentences_to_process_indices)\n","        print(f\"ü§ñ Starting fresh classification of {sentences_count} sentences...\")\n","\n","\n","    if not sentences_count:\n","        print(\"‚úÖ No sentences need processing!\")\n","        results_df = sample_df # Ensure results_df is set even if no processing occurs\n","    else:\n","        print(f\"About to classify {sentences_count} sentences\")\n","        print(f\"Estimated cost: FREE (Groq)\")\n","        print(f\"Estimated time: ~{sentences_count * CONFIG['delay'] / 60:.1f} minutes\")\n","        print(f\"Max retries per sentence: {CONFIG['max_retries']}\")\n","        print(f\"Base retry delay: {CONFIG['retry_delay']} seconds\")\n","\n","        proceed = input(\"Proceed with classification? (y/n): \").lower().strip()\n","\n","        if proceed == 'y':\n","            print(\"ü§ñ Starting classification...\")\n","\n","            # Use the original sample_df as the base for results_df to keep all rows\n","            results_df = sample_df.copy()\n","\n","            # Process sentences with progress bar, iterating only over selected indices\n","            processed_count = (results_df['processing_status'] == 'completed').sum() if 'processing_status' in results_df.columns else 0 # Start count from existing completions\n","            total_to_process_in_this_run = sentences_count # Total number of sentences that will enter the loop\n","\n","            print(f\"Starting processing loop for {total_to_process_in_this_run} sentences...\")\n","\n","            for idx in tqdm(sentences_to_process_indices, desc=\"üîç Classifying\"):\n","                sentence = results_df.loc[idx, 'sentence'] # Use results_df to get the sentence\n","\n","                # Skip if sentence is too short (already handled in the method, but good practice)\n","                if pd.isna(sentence) or len(sentence.strip()) < 10:\n","                    results_df.at[idx, 'processing_status'] = \"skipped_short\"\n","                    continue\n","\n","                try:\n","                    # Query Groq API with retry logic\n","                    classification, explanation = classifier.query_groq_with_retry(sentence)\n","\n","                    # Store results\n","                    results_df.at[idx, 'is_climate_LLM'] = classification\n","                    results_df.at[idx, 'llm_explanation'] = explanation\n","                    results_df.at[idx, 'processing_status'] = \"completed\"\n","\n","                    # Rate limiting\n","                    time.sleep(CONFIG['delay'])\n","\n","                    # Save checkpoint - Use total completed count for filename\n","                    current_completed_count = (results_df['processing_status'] == 'completed').sum()\n","                    if current_completed_count % CONFIG['batch_size'] == 0 and current_completed_count > processed_count:\n","                         save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","                         checkpoint_file = f\"{save_path}checkpoint_processed_{current_completed_count}.csv\"\n","                         try:\n","                             results_df.to_csv(checkpoint_file, index=False)\n","                             print(f\"\\nüíæ Checkpoint saved: {current_completed_count}/{len(results_df)} total completed at {checkpoint_file}\")\n","                         except Exception as e:\n","                              print(f\"\\n‚ö†Ô∏è Could not save checkpoint to {checkpoint_file}: {e}\")\n","                              try:\n","                                  local_checkpoint_file = f\"./checkpoint_processed_{current_completed_count}_local.csv\"\n","                                  results_df.to_csv(local_checkpoint_file, index=False)\n","                                  print(f\"üíæ Checkpoint saved locally: {local_checkpoint_file}\")\n","                              except Exception as local_e:\n","                                  print(f\"‚ùå Could not save checkpoint locally either: {local_e}\")\n","\n","                    processed_count = current_completed_count # Update processed_count after potential save\n","\n","                except Exception as e:\n","                    logger.error(f\"Error processing sentence {idx}: {str(e)}\")\n","                    results_df.at[idx, 'processing_status'] = f\"error: {str(e)}\"\n","                    results_df.at[idx, 'llm_explanation'] = str(e)\n","\n","            print(f\"üéâ Processing complete! Processed {total_to_process_in_this_run} sentences in this run.\")\n","\n","            # Save final results\n","            save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","            results_file = f\"{save_path}climate_classification_results.csv\"\n","            try:\n","                results_df.to_csv(results_file, index=False)\n","                print(f\"üíæ Results saved: {results_file}\")\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Could not save to drive: {e}\")\n","                local_results_file = \"./climate_classification_results_local.csv\"\n","                results_df.to_csv(local_results_file, index=False)\n","                print(f\"üíæ Results saved locally: {local_results_file}\")\n","\n","        else:\n","            print(\"‚ùå Classification cancelled\")\n","            # Ensure results_df is set to the initial sample_df if cancelled\n","            results_df = sample_df.copy()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a0cc1553"},"outputs":[],"source":["# Cell 8: Generate Summary Statistics\n","if 'results_df' in locals():\n","    print(\"üìä Generating Summary Statistics\")\n","    print(\"-\" * 35)\n","\n","    # Generate stats\n","    stats = classifier.generate_summary_stats(results_df)\n","\n","    # Display results\n","    print(\"üéØ CLASSIFICATION SUMMARY\")\n","    print(\"=\" * 40)\n","    print(f\"Total sentences processed: {stats['total_sentences']:,}\")\n","    print(f\"Climate mitigation sentences: {stats['climate_mitigation_sentences']:,} ({stats['climate_percentage']}%)\")\n","    print(f\"Non-climate sentences: {stats['non_climate_sentences']:,}\")\n","    print(f\"Processing success rate: {stats['processing_success_rate']}%\")\n","\n","    # Processing status breakdown\n","    print(f\"\\nüìà PROCESSING STATUS:\")\n","    print(f\"‚úÖ Completed: {stats['completed_sentences']:,}\")\n","    print(f\"‚ùå Failed: {stats['failed_sentences']:,}\")\n","    print(f\"‚è≥ Pending: {stats['pending_sentences']:,}\")\n","\n","    print(\"\\nüèõÔ∏è  BY INSTITUTION:\")\n","    if 'by_institution' in stats:\n","        for institution, data in stats['by_institution']['Climate_%'].items():\n","            total = stats['by_institution']['Total'][institution]\n","            climate = stats['by_institution']['Climate'][institution]\n","            print(f\"   {institution}: {climate}/{total} ({data}%)\")\n","\n","    print(\"\\nüìö BY DICTIONARY TERMS:\")\n","    if 'by_dictionary_presence' in stats:\n","        for category, data in stats['by_dictionary_presence']['Climate_%'].items():\n","            total = stats['by_dictionary_presence']['Total'][category]\n","            climate = stats['by_dictionary_presence']['Climate'][category]\n","            print(f\"   {category}: {climate}/{total} ({data}%)\")\n","\n","    # Show error breakdown if there are failed sentences\n","    if stats['failed_sentences'] > 0:\n","        print(f\"\\n‚ùå ERROR BREAKDOWN:\")\n","        error_mask = results_df['processing_status'].str.contains('error', na=False)\n","        if error_mask.any():\n","            error_types = results_df[error_mask]['llm_explanation'].value_counts()\n","            for error, count in error_types.head(5).items():\n","                print(f\"   ‚Ä¢ {error}: {count} cases\")\n","\n","    # Save stats\n","    save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","    stats_file = f\"{save_path}classification_summary.json\"\n","    try:\n","        with open(stats_file, 'w') as f:\n","            json.dump(stats, f, indent=2, default=str)\n","        print(f\"\\nüíæ Statistics saved: {stats_file}\")\n","    except Exception as e:\n","        print(f\"\\n‚ö†Ô∏è Could not save statistics to drive: {e}\")\n","        try:\n","            local_stats_file = \"./classification_summary_local.json\"\n","            with open(local_stats_file, 'w') as f:\n","                json.dump(stats, f, indent=2, default=str)\n","            print(f\"üíæ Statistics saved locally: {local_stats_file}\")\n","        except Exception as local_e:\n","            print(f\"‚ùå Could not save statistics locally either: {local_e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bdb50482"},"outputs":[],"source":["# Cell 9: Sample Results Preview\n","if 'results_df' in locals():\n","    print(\"\\nüîç Sample Results Preview\")\n","    print(\"-\" * 30)\n","\n","    # Show some climate mitigation examples\n","    climate_examples = results_df[results_df['is_climate_LLM'] == 1].head(3)\n","    non_climate_examples = results_df[results_df['is_climate_LLM'] == 0].head(3)\n","\n","    if len(climate_examples) > 0:\n","        print(\"‚úÖ Climate Mitigation Examples:\")\n","        for idx, row in climate_examples.iterrows():\n","            print(f\"   ‚Ä¢ {row['current'][:80]}...\")\n","            if len(row['llm_explanation']) > 60:\n","                print(f\"     ‚Üí {row['llm_explanation'][:60]}...\\n\")\n","            else:\n","                print(f\"     ‚Üí {row['llm_explanation']}\\n\")\n","\n","    if len(non_climate_examples) > 0:\n","        print(\"‚ùå Non-Climate Examples:\")\n","        for idx, row in non_climate_examples.iterrows():\n","            print(f\"   ‚Ä¢ {row['current'][:80]}...\")\n","            if len(row['llm_explanation']) > 60:\n","                print(f\"     ‚Üí {row['llm_explanation'][:60]}...\\n\")\n","            else:\n","                print(f\"     ‚Üí {row['llm_explanation']}\\n\")\n","\n","    # Show failed examples if any\n","    failed_examples = results_df[results_df['processing_status'].str.contains('error', na=False)].head(3)\n","    if len(failed_examples) > 0:\n","        print(\"‚ö†Ô∏è Failed Classification Examples:\")\n","        for idx, row in failed_examples.iterrows():\n","            print(f\"   ‚Ä¢ {row['current'][:80]}...\")\n","            print(f\"     ‚Üí Status: {row['processing_status']}\")\n","            print(f\"     ‚Üí Error: {row['llm_explanation'][:60]}...\\n\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1e06a6ea"},"outputs":[],"source":["# Cell 10: Retry Failed Classifications\n","if 'results_df' in locals():\n","    print(\"üîÑ Retry Failed Classifications\")\n","    print(\"-\" * 35)\n","\n","    # Check for failed classifications\n","    failed_mask = (\n","        results_df['llm_explanation'].str.contains('Error:', na=False) |\n","        results_df['processing_status'].str.contains('error', na=False) |\n","        (results_df['processing_status'] == 'pending')\n","    )\n","    failed_count = failed_mask.sum()\n","\n","    if failed_count > 0:\n","        print(f\"Found {failed_count} failed/pending classifications\")\n","\n","        # Show error types\n","        print(\"Error breakdown:\")\n","        error_types = results_df[failed_mask]['llm_explanation'].value_counts()\n","        for error, count in error_types.head(10).items():\n","            print(f\"   ‚Ä¢ {error}: {count} cases\")\n","\n","        retry_choice = input(f\"\\nRetry these {failed_count} failed classifications? (y/n): \").lower().strip()\n","\n","        if retry_choice == 'y':\n","            print(\"üîÑ Starting retry process...\")\n","\n","            # Ask for modified retry settings\n","            print(f\"Current retry settings:\")\n","            print(f\"   Max retries: {CONFIG['max_retries']}\")\n","            print(f\"   Base delay: {CONFIG['retry_delay']} seconds\")\n","            print(f\"   Request delay: {CONFIG['delay']} seconds\")\n","\n","            modify_settings = input(\"Modify retry settings? (y/n): \").lower().strip()\n","\n","            if modify_settings == 'y':\n","                try:\n","                    new_delay = float(input(f\"Request delay ({CONFIG['delay']}): \") or CONFIG['delay'])\n","                    new_retry_delay = int(input(f\"Base retry delay ({CONFIG['retry_delay']}): \") or CONFIG['retry_delay'])\n","                    new_max_retries = int(input(f\"Max retries ({CONFIG['max_retries']}): \") or CONFIG['max_retries'])\n","\n","                    CONFIG['delay'] = new_delay\n","                    CONFIG['retry_delay'] = new_retry_delay\n","                    CONFIG['max_retries'] = new_max_retries\n","\n","                    print(f\"‚úÖ Updated settings: delay={new_delay}s, retry_delay={new_retry_delay}s, max_retries={new_max_retries}\")\n","                except ValueError:\n","                    print(\"‚ö†Ô∏è Invalid input, using current settings\")\n","\n","            # Create new classifier with updated settings\n","            retry_classifier = ClimateMitigationClassifier(\n","                CONFIG['groq_api_key'],\n","                CONFIG['groq_model'],\n","                CONFIG['max_retries'],\n","                CONFIG['retry_delay'],\n","                CONFIG['backoff_multiplier']\n","            )\n","\n","            # Retry failed classifications\n","            retry_results_df = retry_classifier.classify_sentences(\n","                results_df,\n","                sentence_col='current',\n","                batch_size=CONFIG['batch_size'],\n","                delay=CONFIG['delay'],\n","                reclassify_failed=True\n","            )\n","\n","            # Update results\n","            results_df = retry_results_df\n","\n","            # Show retry results\n","            new_failed_count = (\n","                results_df['llm_explanation'].str.contains('Error:', na=False) |\n","                results_df['processing_status'].str.contains('error', na=False) |\n","                (results_df['processing_status'] == 'pending')\n","            ).sum()\n","\n","            print(f\"\\nüéâ Retry complete!\")\n","            print(f\"   Previous failed: {failed_count}\")\n","            print(f\"   Still failed: {new_failed_count}\")\n","            print(f\"   Successfully retried: {failed_count - new_failed_count}\")\n","\n","            # Save updated results\n","            save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","            retry_results_file = f\"{save_path}climate_classification_results_retried.csv\"\n","            try:\n","                results_df.to_csv(retry_results_file, index=False)\n","                print(f\"üíæ Updated results saved: {retry_results_file}\")\n","            except Exception as e:\n","                print(f\"‚ö†Ô∏è Could not save to drive: {e}\")\n","                local_retry_file = \"./climate_classification_results_retried_local.csv\"\n","                results_df.to_csv(local_retry_file, index=False)\n","                print(f\"üíæ Updated results saved locally: {local_retry_file}\")\n","\n","        else:\n","            print(\"‚ùå Retry cancelled\")\n","    else:\n","        print(\"‚úÖ No failed classifications found!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35b011c7"},"outputs":[],"source":["# Cell 11: Download Results\n","print(\"\\nüì• Download Results\")\n","print(\"-\" * 20)\n","\n","if 'results_df' in locals():\n","    print(\"Your results are ready for download!\")\n","    print(\"Files available:\")\n","    print(\"1. üìä climate_classification_results.csv - Full results with classifications\")\n","    print(\"2. üìà classification_summary.json - Summary statistics\")\n","    print(\"3. üéØ stratified_sample.csv - Original sample used (if applicable)\")\n","\n","    # Show final statistics\n","    completed_count = (results_df['processing_status'] == 'completed').sum()\n","    total_count = len(results_df)\n","    success_rate = round(completed_count / total_count * 100, 2) if total_count > 0 else 0\n","\n","    print(f\"\\nüìä Final Statistics:\")\n","    print(f\"   Total sentences: {total_count:,}\")\n","    print(f\"   Successfully processed: {completed_count:,} ({success_rate}%)\")\n","    print(f\"   Climate mitigation: {(results_df['is_climate_LLM'] == 1).sum():,}\")\n","\n","    # Option to download directly\n","    download_choice = input(\"\\nDownload results now? (y/n): \").lower().strip()\n","\n","    if download_choice == 'y':\n","        save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","\n","        # Download main results\n","        try:\n","            files.download(f\"{save_path}climate_classification_results.csv\")\n","            print(\"‚úÖ Results downloaded!\")\n","        except:\n","            try:\n","                files.download(\"./climate_classification_results_local.csv\")\n","                print(\"‚úÖ Local results downloaded!\")\n","            except Exception as e:\n","                print(f\"‚ùå Could not download results: {e}\")\n","\n","        # Option to download summary\n","        download_summary = input(\"Download summary stats? (y/n): \").lower().strip()\n","        if download_summary == 'y':\n","            try:\n","                files.download(f\"{save_path}classification_summary.json\")\n","                print(\"‚úÖ Summary downloaded!\")\n","            except:\n","                try:\n","                    files.download(\"./classification_summary_local.json\")\n","                    print(\"‚úÖ Local summary downloaded!\")\n","                except Exception as e:\n","                    print(f\"‚ùå Could not download summary: {e}\")\n","\n","    print(f\"\\nüìÅ All files are also saved in your Google Drive: {DRIVE_PATH}\")\n","else:\n","    print(\"‚ùå No results available. Please run the classification first.\")\n","\n","print(\"\\nüéâ Climate Mitigation Classification Pipeline Complete!\")\n","print(\"=\" * 60)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7fe9de73"},"outputs":[],"source":["# Cell 12: Quick Status Check Function\n","def check_classification_status(df):\n","    \"\"\"Quick function to check the status of classifications\"\"\"\n","    if df is None:\n","        print(\"‚ùå No data loaded\")\n","        return\n","\n","    print(\"üìä Classification Status Check\")\n","    print(\"-\" * 30)\n","\n","    # Basic counts\n","    total = len(df)\n","    print(f\"Total sentences: {total:,}\")\n","\n","    if 'processing_status' in df.columns:\n","        status_counts = df['processing_status'].value_counts()\n","        print(\"\\nProcessing Status:\")\n","        for status, count in status_counts.items():\n","            percentage = round(count / total * 100, 2)\n","            print(f\"   {status}: {count:,} ({percentage}%)\")\n","\n","    if 'is_climate_LLM' in df.columns:\n","        climate_count = (df['is_climate_LLM'] == 1).sum()\n","        print(f\"\\nClassification Results:\")\n","        print(f\"   Climate mitigation: {climate_count:,} ({round(climate_count/total*100, 2)}%)\")\n","        print(f\"   Non-climate: {total - climate_count:,} ({round((total-climate_count)/total*100, 2)}%)\")\n","\n","    if 'llm_explanation' in df.columns:\n","        # Check for errors\n","        error_mask = df['llm_explanation'].str.contains('Error:', na=False)\n","        error_count = error_mask.sum()\n","        if error_count > 0:\n","            print(f\"\\nErrors found: {error_count:,}\")\n","            print(\"Top error types:\")\n","            error_types = df[error_mask]['llm_explanation'].value_counts()\n","            for error, count in error_types.head(5).items():\n","                print(f\"   ‚Ä¢ {error}: {count}\")\n","\n","# Usage example:\n","# check_classification_status(results_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c2b0589e"},"outputs":[],"source":["# Cell 13: Randomly Sample Classified Sentences\n","if 'results_df' in locals() and results_df is not None:\n","    print(\"\\nüìã Randomly Sampling Classified Sentences\")\n","    print(\"-\" * 45)\n","\n","    sample_size = 1000\n","\n","    if len(results_df) >= sample_size:\n","        random_sample_df = results_df.sample(n=sample_size, random_state=42)\n","        print(f\"‚úÖ Successfully sampled {sample_size} sentences from the classified results.\")\n","\n","        # Display the head of the sampled data\n","        print(\"\\nSampled Data Head:\")\n","        display(random_sample_df.head())\n","\n","        # Optionally save the random sample\n","        save_path = DRIVE_PATH if 'DRIVE_PATH' in globals() and DRIVE_PATH is not None else './'\n","        random_sample_file = f\"{save_path}random_classified_sample_{sample_size}.csv\"\n","        try:\n","            random_sample_df.to_csv(random_sample_file, index=False)\n","            print(f\"\\nüíæ Random sample saved: {random_sample_file}\")\n","        except Exception as e:\n","            print(f\"\\n‚ö†Ô∏è Could not save random sample to drive: {e}\")\n","            try:\n","                local_random_sample_file = f\"./random_classified_sample_{sample_size}_local.csv\"\n","                random_sample_df.to_csv(local_random_sample_file, index=False)\n","                print(f\"üíæ Random sample saved locally: {local_random_sample_file}\")\n","            except Exception as local_e:\n","                print(f\"‚ùå Could not save random sample locally either: {local_e}\")\n","\n","    else:\n","        print(f\"‚ö†Ô∏è The total number of classified sentences ({len(results_df)}) is less than the requested sample size ({sample_size}). Skipping random sampling.\")\n","\n","else:\n","    print(\"‚ùå No classified results available (results_df not found). Skipping random sampling.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"executionInfo":{"elapsed":57,"status":"error","timestamp":1751371838121,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"q1WvhPRR5Uc-","outputId":"f0af2335-1dd0-4350-d08d-c09f1edb5b77"},"outputs":[{"ename":"AttributeError","evalue":"'NoneType' object has no attribute 'head'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-9-861558764.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'head'"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":608},"executionInfo":{"elapsed":957,"status":"ok","timestamp":1751371860103,"user":{"displayName":"Bartu Turan","userId":"02382104729079309124"},"user_tz":-120},"id":"tvt8nPqC5V_u","outputId":"50376be3-c858-4157-da18-1cac2ee2bdab"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/google/colab/_dataframe_summarizer.py:88: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n","  cast_date_col = pd.to_datetime(column, errors=\"coerce\")\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"df\",\n  \"rows\": 33297,\n  \"fields\": [\n    {\n      \"column\": \"new_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60,\n        \"min\": 1,\n        \"max\": 267,\n        \"num_unique_values\": 267,\n        \"samples\": [\n          85,\n          47,\n          184\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 1,\n        \"max\": 238,\n        \"num_unique_values\": 236,\n        \"samples\": [\n          72,\n          192,\n          189\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total_sentences_in_doc\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 2,\n        \"max\": 238,\n        \"num_unique_values\": 167,\n        \"samples\": [\n          133,\n          171,\n          124\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32699,\n        \"samples\": [\n          \"It welcomed the Iraqi determination to continue the political process and assured the Prime Minister that the European Union will continue to support the brave and difficult course the people of Iraq are steering towards the restoration of security, democracy and the rule of law.\",\n          \"ENLARGEMENT 6.450 9.030 11.610 14.200 16.780 Agriculture 1.600 2.030 2.450 2.930 3.400 Structural operations 3.750 5.830 7.920 10.000 12.080 Internal policies 730 760 790 820 850 Administration 370 410 450 450 450 TOTAL APPROPRIATIONS FOR COMMITMENTS 91995 93385 100255 102035 103075 104995 107040 TOTAL APPROPRIATIONS FOR PAYMENTS 89590 91070 98270 101450 100610 101350 103530 of which: enlargement 4.140 6.710 8.890 11.440 14.220 Appropriations for payments as % of GNP 1,13% 1,12% 1,14% 1,15% 1,11% 1,09% 1,09% Margin 0,14% 0,15% 0,13% 0,12% 0,16% 0,18% 0,18% Own resources ceiling 1,27% 1,27% 1,27% 1,27% 1,27% 1,27% 1,27% PART II - DECLARATION ON THE APPOINTMENT OF THE PRESIDENT OF THE COMMISSION I. The Heads of State or Government have noted with respect the resignation of the Commission and expressed their thanks for the work done for Europe.\",\n          \"Namibia The European, Council has -taken note of the proposal for a settlement in Namibia prepared by the Five Powers, The Council supports the action of the Five and considers the proposal to be a fair and reasonable settlement.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id_within\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 9,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filename\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 407,\n        \"samples\": [\n          \"1992_06.pdf_3\",\n          \"2006_12.pdf_3\",\n          \"2011_03c.pdf_2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"date corrected, check file order and naming\",\n          \"Date is imputed, we do not know teh day.\",\n          \"Venue corrected, date corrected\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"venue\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 45,\n        \"samples\": [\n          \"Laeken\",\n          \"Essen\",\n          \"Cannes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1975-03-14 00:00:00\",\n        \"max\": \"2067-07-07 00:00:00\",\n        \"num_unique_values\": 116,\n        \"samples\": [\n          \"5/9/19\",\n          \"7/22/76\",\n          \"5/23/12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"start_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 252,\n        \"samples\": [\n          \"3/19/15\",\n          \"12/9/74\",\n          \"3/13/08\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"end_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 251,\n        \"samples\": [\n          \"10/25/13\",\n          \"12/10/74\",\n          \"2/12/15\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 1961,\n        \"max\": 2023,\n        \"num_unique_values\": 55,\n        \"samples\": [\n          2000,\n          1974,\n          2001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"type_document\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Meeting statement\",\n          \"Summit statement\",\n          \"Presidency conclusion\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 259,\n        \"samples\": [\n          \"PRESIDENCYCONCLUSIONS\",\n          \"CONCLUSIONS OF THE PRESIDENCY EUROPEAN COUNCIL\\n\\nSTRASBOURG, 8 AND 9 DECEMBER 1989\",\n          \"CONCLUSIONS BRAWN UP BY THE PRESIDENCY\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"how_many_words_in_climate_mitigation_dictionary\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"},"text/html":["\n","  <div id=\"df-2d6898fa-f286-491f-8be5-60c0669f7818\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>new_id</th>\n","      <th>sentence_id</th>\n","      <th>total_sentences_in_doc</th>\n","      <th>sentence</th>\n","      <th>id_within</th>\n","      <th>filename</th>\n","      <th>notes</th>\n","      <th>venue</th>\n","      <th>date</th>\n","      <th>start_date</th>\n","      <th>end_date</th>\n","      <th>year</th>\n","      <th>type_document</th>\n","      <th>title</th>\n","      <th>how_many_words_in_climate_mitigation_dictionary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>13</td>\n","      <td>The Heads of State or of Government and the Fo...</td>\n","      <td>1</td>\n","      <td>1961_02.pdf</td>\n","      <td>None</td>\n","      <td>Luxembourg</td>\n","      <td>None</td>\n","      <td>2/10/61</td>\n","      <td>2/11/61</td>\n","      <td>1961</td>\n","      <td>Meeting statement</td>\n","      <td>Conference of the Heads of State or of Governm...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>13</td>\n","      <td>Special links already unite the six countries ...</td>\n","      <td>1</td>\n","      <td>1961_02.pdf</td>\n","      <td>None</td>\n","      <td>Luxembourg</td>\n","      <td>None</td>\n","      <td>2/10/61</td>\n","      <td>2/11/61</td>\n","      <td>1961</td>\n","      <td>Meeting statement</td>\n","      <td>Conference of the Heads of State or of Governm...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>13</td>\n","      <td>The six Governments are anx¬¨ious to seek, in a...</td>\n","      <td>1</td>\n","      <td>1961_02.pdf</td>\n","      <td>None</td>\n","      <td>Luxembourg</td>\n","      <td>None</td>\n","      <td>2/10/61</td>\n","      <td>2/11/61</td>\n","      <td>1961</td>\n","      <td>Meeting statement</td>\n","      <td>Conference of the Heads of State or of Governm...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>13</td>\n","      <td>They will attempt, in the same spirit, to find...</td>\n","      <td>1</td>\n","      <td>1961_02.pdf</td>\n","      <td>None</td>\n","      <td>Luxembourg</td>\n","      <td>None</td>\n","      <td>2/10/61</td>\n","      <td>2/11/61</td>\n","      <td>1961</td>\n","      <td>Meeting statement</td>\n","      <td>Conference of the Heads of State or of Governm...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>13</td>\n","      <td>It was the purpose of the Conference to seek t...</td>\n","      <td>1</td>\n","      <td>1961_02.pdf</td>\n","      <td>None</td>\n","      <td>Luxembourg</td>\n","      <td>None</td>\n","      <td>2/10/61</td>\n","      <td>2/11/61</td>\n","      <td>1961</td>\n","      <td>Meeting statement</td>\n","      <td>Conference of the Heads of State or of Governm...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2d6898fa-f286-491f-8be5-60c0669f7818')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2d6898fa-f286-491f-8be5-60c0669f7818 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2d6898fa-f286-491f-8be5-60c0669f7818');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-99b0de77-85cf-4b0d-a82f-354d9369922d\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-99b0de77-85cf-4b0d-a82f-354d9369922d')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-99b0de77-85cf-4b0d-a82f-354d9369922d button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["   new_id  sentence_id  total_sentences_in_doc  \\\n","0       1            1                      13   \n","1       1            2                      13   \n","2       1            3                      13   \n","3       1            4                      13   \n","4       1            5                      13   \n","\n","                                            sentence  id_within     filename  \\\n","0  The Heads of State or of Government and the Fo...          1  1961_02.pdf   \n","1  Special links already unite the six countries ...          1  1961_02.pdf   \n","2  The six Governments are anx¬¨ious to seek, in a...          1  1961_02.pdf   \n","3  They will attempt, in the same spirit, to find...          1  1961_02.pdf   \n","4  It was the purpose of the Conference to seek t...          1  1961_02.pdf   \n","\n","  notes       venue  date start_date end_date  year      type_document  \\\n","0  None  Luxembourg  None    2/10/61  2/11/61  1961  Meeting statement   \n","1  None  Luxembourg  None    2/10/61  2/11/61  1961  Meeting statement   \n","2  None  Luxembourg  None    2/10/61  2/11/61  1961  Meeting statement   \n","3  None  Luxembourg  None    2/10/61  2/11/61  1961  Meeting statement   \n","4  None  Luxembourg  None    2/10/61  2/11/61  1961  Meeting statement   \n","\n","                                               title  \\\n","0  Conference of the Heads of State or of Governm...   \n","1  Conference of the Heads of State or of Governm...   \n","2  Conference of the Heads of State or of Governm...   \n","3  Conference of the Heads of State or of Governm...   \n","4  Conference of the Heads of State or of Governm...   \n","\n","   how_many_words_in_climate_mitigation_dictionary  \n","0                                                0  \n","1                                                0  \n","2                                                0  \n","3                                                0  \n","4                                                0  "]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_feather('/content/drive/MyDrive/Climate Mitigation Council Sentences/Council_sentences_climdict_filtered.feather')\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PNvA4DTx5cQU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN8VH3sm86pMKSf+bEpxsSf"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}